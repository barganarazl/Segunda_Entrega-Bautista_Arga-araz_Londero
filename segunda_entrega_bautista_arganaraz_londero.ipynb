{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalación de librerías:\n",
    "\n",
    "%pip install pandas\n",
    "%pip install requests\n",
    "%pip install psycopg2\n",
    "%pip install datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación de librerías a utilizar:\n",
    "\n",
    "import os\n",
    "import datetime\n",
    "import json\n",
    "import pandas as pd\n",
    "import requests as req\n",
    "import psycopg2 as pg2\n",
    "from psycopg2.extras import execute_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seteo de variables presentes en el archivo '.env' y en el archivo 'variables.json':\n",
    "\n",
    "CLAVE_API = os.environ.get(\"API_KEY\")\n",
    "USUARIO_BD = os.environ.get(\"DB_USER\")\n",
    "CONTRASENA_BD = os.environ.get(\"DB_PASSWORD\")\n",
    "HOST_BD = os.environ.get(\"DB_HOST\")\n",
    "PUERTO_BD = os.environ.get(\"DB_PORT\")\n",
    "NOMBRE_BD = os.environ.get(\"DB_NAME\")\n",
    "\n",
    "with open('variables.json') as json_file:\n",
    "        variables_json = json.load(json_file)\n",
    "\n",
    "nombres = variables_json[\"Nombres_Empresas\"]\n",
    "columnas_df = variables_json[\"Columnas_DataFrame\"]\n",
    "dict_aws = variables_json[\"Columnas_Redshift\"]\n",
    "list_aws = list(variables_json[\"Columnas_Redshift\"].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración para mostrar un número definido de registros y campos\n",
    "\n",
    "pd.set_option('display.max_rows', 10)\n",
    "pd.set_option('display.max_columns', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracción desde la API de los datos diarios de \"Los 7 Magníficos\" (Alphabet, Amazon, Apple, Meta, Microsoft, Nvidia y Tesla) correspondiente al NASDAQ tomando en cuenta el último año (sin contar Sabados y Domingos):\n",
    "\n",
    "api = 'https://api.twelvedata.com/time_series?symbol=GOOGL,AMZN,AAPL,META,MSFT,NVDA,TSLA&exchange=NASDAQ&interval=1day&format=JSON&outputsize=260&apikey=' + CLAVE_API\n",
    "peticion = req.get(api)\n",
    "\n",
    "peticion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversión de datos a formato JSON:\n",
    "\n",
    "datos_json = peticion.json()\n",
    "\n",
    "datos_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalización de datos y agregado de columnas:\n",
    "\n",
    "datos_df = pd.DataFrame()\n",
    "claves = list(datos_json.keys())\n",
    "contador = 0\n",
    "\n",
    "for empresa in datos_json:\n",
    "    tabla = pd.json_normalize(datos_json[empresa]['values'])\n",
    "    tabla['Codigo'] = claves[contador]\n",
    "    tabla['Empresa'] = nombres[claves[contador]]\n",
    "    datos_df = pd.concat([datos_df, tabla], axis = 0)\n",
    "    contador += 1\n",
    "\n",
    "datos_df.columns = columnas_df\n",
    "\n",
    "datos_df = datos_df.drop_duplicates()\n",
    "datos_df = datos_df.sort_values(by = ['Dia', 'Empresa'], ascending = [False, True],ignore_index = True)\n",
    "\n",
    "datos_df['Clave_Compuesta'] = datos_df.Codigo.str.cat(datos_df.Dia)\n",
    "datos_df['Columna_Temporal'] = datetime.datetime.now()\n",
    "\n",
    "datos_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conexión a la base de datos en Amazon Redshift y creación del cursor:\n",
    "\n",
    "try:\n",
    "    conexion = pg2.connect(host = HOST_BD, port = PUERTO_BD, dbname = NOMBRE_BD, user = USUARIO_BD, password = CONTRASENA_BD)\n",
    "    print('Conexión exitosa a la base de datos.')\n",
    "except Exception as e:\n",
    "    print('Conexión fallida a la base de datos.')\n",
    "    print(e)\n",
    "\n",
    "cursor = conexion.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creación de las tablas principal y staging en Amazon Redshift:\n",
    "\n",
    "columnas_query_create = ''\n",
    "contador_create = 1\n",
    "\n",
    "for i in dict_aws:\n",
    "        if contador_create != len(dict_aws):\n",
    "                columnas_query_create = columnas_query_create + i + ' ' + dict_aws[i] + ','\n",
    "        else:\n",
    "                columnas_query_create = columnas_query_create + i + ' ' + dict_aws[i]\n",
    "        contador_create += 1\n",
    "\n",
    "query_create = 'CREATE TABLE IF NOT EXISTS b_arganaraz_londero_coderhouse.cotizacion_magnificos(' + columnas_query_create + ');' + '''\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS b_arganaraz_londero_coderhouse.cotizacion_magnificos_staging(''' + columnas_query_create + ');'\n",
    "\n",
    "cursor.execute(query_create)\n",
    "conexion.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insercion de datos a la tabla staging creada en Amazon Redshift:\n",
    "\n",
    "columnas_query_insert = ''\n",
    "contador_insert = 1\n",
    "\n",
    "for x in dict_aws:\n",
    "        if contador_insert != len(dict_aws):\n",
    "                columnas_query_insert = columnas_query_insert + x + ', '\n",
    "        else:\n",
    "                columnas_query_insert = columnas_query_insert + x\n",
    "        contador_insert += 1\n",
    "\n",
    "query_insert = 'INSERT INTO b_arganaraz_londero_coderhouse.cotizacion_magnificos_staging(' + columnas_query_insert + ') VALUES %s;'\n",
    "\n",
    "valores = [tuple(var) for var in datos_df[list_aws].to_numpy()]\n",
    "execute_values(cursor, query_insert, valores)\n",
    "conexion.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actualización incremental de la tabla principal en base a los datos de la tabla staging en Amazon Redshift:\n",
    "\n",
    "query_incremental = '''\n",
    "DELETE FROM b_arganaraz_londero_coderhouse.cotizacion_magnificos \n",
    "USING b_arganaraz_londero_coderhouse.cotizacion_magnificos_staging \n",
    "WHERE b_arganaraz_londero_coderhouse.cotizacion_magnificos.Clave_Compuesta = b_arganaraz_londero_coderhouse.cotizacion_magnificos_staging.Clave_Compuesta;\n",
    "\n",
    "INSERT INTO b_arganaraz_londero_coderhouse.cotizacion_magnificos SELECT * FROM b_arganaraz_londero_coderhouse.cotizacion_magnificos_staging;\n",
    "\n",
    "DROP TABLE b_arganaraz_londero_coderhouse.cotizacion_magnificos_staging;\n",
    "'''\n",
    "\n",
    "cursor.execute(query_incremental)\n",
    "conexion.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccion de los datos insertados a la tabla creada en Amazon Redshift para comprobación de carga correcta:\n",
    "\n",
    "query_seleccion = '''\n",
    "        SELECT * FROM b_arganaraz_londero_coderhouse.cotizacion_magnificos\n",
    "        '''\n",
    "\n",
    "cursor.execute(query_seleccion)\n",
    "conexion.commit()\n",
    "resultados = cursor.fetchall()\n",
    "\n",
    "resultados = pd.DataFrame(resultados)\n",
    "resultados.columns = list_aws\n",
    "resultados.set_index('Clave_Compuesta', inplace = True)\n",
    "\n",
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cierre de cursor y conexión:\n",
    "\n",
    "cursor.close()\n",
    "conexion.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
